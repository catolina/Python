{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PanTadueszNoweZwrotki.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/catolina/Python/blob/master/PanTadueszNoweZwrotki.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3e7xTR9E41y",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "# from https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py\n",
        "\n",
        "'''Example script to generate text from Nietzsche's writings.\n",
        "At least 20 epochs are required before the generated text\n",
        "starts sounding coherent.\n",
        "It is recommended to run this script on GPU, as recurrent\n",
        "networks are quite computationally intensive.\n",
        "If you try this script on new data, make sure your corpus\n",
        "has at least ~100k characters. ~1M is better.\n",
        "'''\n",
        "\n",
        "import io\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers import LSTM\n",
        "from keras.models import Sequential\n",
        "from keras.utils.data_utils import get_file\n",
        "\n",
        "# pobranie pliku z Panem Tadeuszem\n",
        "path = get_file('pantadeusz.txt', origin='https://wolnelektury.pl/media/book/txt/pan-tadeusz.txt')\n",
        "with io.open(path, encoding='utf-8') as f:\n",
        "    text = f.read().lower()\n",
        "\n",
        "# długość Pana Tadeusza w znakach\n",
        "print('corpus length:', len(text))\n",
        "\n",
        "# lista wszystkich występujących znaków\n",
        "chars = sorted(set(text))\n",
        "# liczba wszystkich występujących znaków\n",
        "print('total chars:', len(chars))\n",
        "\n",
        "# mapowanie ze znaku na liczbę i odwrotne\n",
        "char_to_index = {c: i for i, c in enumerate(chars)}\n",
        "index_to_char = {i: c for i, c in enumerate(chars)}\n",
        "\n",
        "# długość wejścia\n",
        "sen_len = 40\n",
        "step = 3\n",
        "\n",
        "sentences = []\n",
        "next_chars = []\n",
        "\n",
        "# dane treningowe x = zdanie -> y = kolejna literka\n",
        "for i in range(0, len(text) - sen_len, step):\n",
        "    sentences.append(text[i: i + sen_len])\n",
        "    next_chars.append(text[i + sen_len])\n",
        "print('sequences:', len(sentences))\n",
        "\n",
        "# przygotowanie danych do sieci - tablice numpy one hot\n",
        "x = np.zeros((len(sentences), sen_len, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_to_index[char]] = 1\n",
        "    y[i, char_to_index[next_chars[i]]] = 1\n",
        "\n",
        "# model z jedną warstwą LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(sen_len, len(chars))))\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "\n",
        "# pewien rodzaj magii, pozwala zwrócić nam kolejną literkę, jedną z najbardziej prawdopodobnych\n",
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    # \"odwrócenie softmax\"\n",
        "    preds = np.log(preds) / temperature\n",
        "\n",
        "    # \"softmax\"\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "    # wylosowanie wartości z rozkładu\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "\n",
        "# funkcja będzie wywoływana na koniec każdej epoki\n",
        "def on_epoch_end(epoch, logs):\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "    # z ktorego miejsca wziąć początek do generowania\n",
        "    start_index = random.randint(0, len(text) - sen_len - 1)\n",
        "\n",
        "    # wygenerowany do tej pory tekst\n",
        "    generated = ''\n",
        "    # początek do generowania\n",
        "    sentence = text[start_index: start_index + sen_len]\n",
        "    generated += sentence\n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "\n",
        "    for i in range(400):\n",
        "        # kodowanie zdania do predykcji\n",
        "        x_pred = np.zeros((1, sen_len, len(chars)))\n",
        "        for t, ch in enumerate(sentence):\n",
        "            x_pred[0, t, char_to_index[ch]] = 1.\n",
        "\n",
        "        # predykcja\n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        # wybranie kolejnej literki - brak tej funkcji powoduje generowanie ciągle tego samego tekstu\n",
        "        next_index = sample(preds, 0.2)\n",
        "        next_char = index_to_char[next_index]\n",
        "\n",
        "        # dodanie kolejnej literki do wygenerowanego tekstu\n",
        "        generated += next_char\n",
        "        # \"przesunięcie\" zdania o 1 w prawo\n",
        "        sentence = sentence[1:] + next_char\n",
        "\n",
        "        # wymuszenie wypisania na ekran\n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "\n",
        "\n",
        "# dodatkowy callback, żeby wypisywać tekst po każdej epoce\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
        "\n",
        "model.fit(x, y, batch_size=2048, epochs=100, callbacks=[print_callback])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}